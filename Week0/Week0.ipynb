{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o4BQVnaAHC4F"
      },
      "source": [
        "## PyTorch Tutorial!!!\n",
        "In this assignment, you will be familiarized with the usage of the PyTorch library and how to build a model in two ways  \n",
        "It's quite similar to TensorFlow\n",
        "*   using the inbuilt layers in pytorch\n",
        "*   using custom layers to replicate the same result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "Co1Y3oSoAqHp"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [],
      "source": [
        "# %pip uninstall torch torchvision -y\n",
        "# %pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.7.0+cu118\n",
            "11.8\n"
          ]
        }
      ],
      "source": [
        "print(torch.__version__)  # Look for \"+cpu\" in the version string\n",
        "print(torch.version.cuda)  # Should show CUDA version, not None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Using the GPU if it exists\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n682ZxROHh_1"
      },
      "source": [
        "### Loading and preprocessing the Data\n",
        "We will directly be using the dataset included in literally any library that exists. MNIST really is THAT popular.  \n",
        "Link: https://docs.pytorch.org/vision/0.9/datasets.html#mnist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "8zrkUXY8AvtN"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([transforms.ToTensor()])\n",
        "# transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
        "\n",
        "train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
        "test_dataset = datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, pin_memory=True, num_workers=10)\n",
        "test_loader = DataLoader(test_dataset, batch_size=1000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d6W4VEerGYJ8"
      },
      "source": [
        "## Making a simple feedforward network\n",
        "\n",
        "The following is a simple feedforward model with three layers:\n",
        "* a flatten layer to convert our 28x28 images into a single array of length 784\n",
        "* a dense layer of 128 neurons with the relu activation function\n",
        "* finally a dense layer of 10 neurons with the softmax activation to get a distribution between the digits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zwFnJsE6vjf8",
        "outputId": "ac06dbd4-9873-4366-d212-8d784b6eab77"
      },
      "outputs": [],
      "source": [
        "# Build the model\n",
        "SequentialNet = nn.Sequential(\n",
        "    nn.Flatten(),\n",
        "    nn.Linear(784, 128),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(128, 64),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(64, 10)\n",
        "\n",
        "    #adding softmax decreases accuracy \n",
        "    # beacuse nn.CrossEntropyLoss applies softmax itself\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Training and Testing loops"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Training loop\n",
        "def train(model, loader, optimizer, loss_fn, epochs=5):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0\n",
        "        for x, y in loader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            logits = model(x)\n",
        "            loss = loss_fn(logits, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "        print(f\"Epoch {epoch+1}, Loss: {total_loss:.4f}\")\n",
        "\n",
        "def train_cpu(model, loader, optimizer, loss_fn, epochs=5):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0\n",
        "        for x, y in loader:\n",
        "            # x, y = x.to(device), y.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            logits = model(x)\n",
        "            loss = loss_fn(logits, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "        # print(logits)\n",
        "        print(f\"Epoch {epoch+1}, Loss: {total_loss:.4f}\")\n",
        "\n",
        "# Testing loop\n",
        "def test(model, loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for x, y in loader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            logits = model(x)\n",
        "            pred = logits.argmax(dim=1)\n",
        "            correct += (pred == y).sum().item()\n",
        "            total += y.size(0)\n",
        "    print(f\"Accuracy: {100 * correct / total:.2f}%\")\n",
        "def test_cpu(model, loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for x, y in loader:\n",
        "            # x, y = x.to(device), y.to(device)\n",
        "            logits = model(x)\n",
        "            pred = logits.argmax(dim=1)\n",
        "            correct += (pred == y).sum().item()\n",
        "            total += y.size(0)\n",
        "    print(f\"Accuracy: {100 * correct / total:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Training the sequential model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training SequentialNet\n",
            "Epoch 1, Loss: 196.6392\n",
            "Epoch 2, Loss: 81.3366\n",
            "Epoch 3, Loss: 56.7637\n",
            "Epoch 4, Loss: 42.7512\n",
            "Epoch 5, Loss: 33.9570\n",
            "Epoch 6, Loss: 27.3722\n",
            "Epoch 7, Loss: 22.5118\n",
            "Epoch 8, Loss: 18.9366\n",
            "Epoch 9, Loss: 15.7323\n",
            "Epoch 10, Loss: 12.3793\n",
            "Accuracy: 97.68%\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nTraining SequentialNet\")\n",
        "# sequential_model = SequentialNet.to(device)\n",
        "sequential_model = SequentialNet\n",
        "optimizer_seq = optim.Adam(sequential_model.parameters(), lr=0.001)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, pin_memory=True)\n",
        "# train_loader = DataLoader(train_dataset, batch_size=800, shuffle=True)\n",
        "# train(sequential_model, train_loader, optimizer_seq, loss_fn, epochs=10)\n",
        "train_cpu(sequential_model, train_loader, optimizer_seq, loss_fn, epochs=10)\n",
        "test_cpu(sequential_model, test_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "using cpu, epoch 10, time 55.2 sec, batch size = 128<br>\n",
        "using gpu, epoch 10, time 43.6 sec, batch size = 128<br><br>\n",
        "\n",
        "using cpu, epoch 10, time 35.4 sec, batch size = 256<br>\n",
        "using gpu, epoch 10, time 36.9 sec, batch size = 256<br><br>\n",
        "\n",
        "using cpu, epoch 2, time 7.5 sec, batch size = 10000<br>\n",
        "using gpu, epoch 2, time 6.5 sec, batch size = 10000<br><br>\n",
        "\n",
        "using cpu, epoch 10, time 31 sec, batch size = 50000<br>\n",
        "using gpu, epoch 10, time 33.6 sec, batch size = 50000<br><br>\n",
        "\n",
        "High batch size decrease gpu usage, optimal(still only 20-30% RTX 3050) at around 128, 256 batch size"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dCEMWK1KLZDT"
      },
      "source": [
        "### Manually building the same network from scratch\n",
        "You can use the simple sequential model we described above as a reference."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zw53cAmELYJK"
      },
      "outputs": [],
      "source": [
        "# Custom model\n",
        "class ManualNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ManualNet, self).__init__()\n",
        "        # TODO: Define your paramters using nn.Parameters (the layers)\n",
        "\n",
        "        # change initialization outputs very high compared to sequential net\n",
        "\n",
        "        #this being a list does not allow it to move to gpu when .to() used\n",
        "\n",
        "        self.weights = [torch.nn.Parameter(torch.rand((784, 128))-0.5),\n",
        "                        torch.nn.Parameter(torch.rand((128, 64))-0.5),\n",
        "                        torch.nn.Parameter(torch.rand((64, 10))-0.5)]\n",
        "\n",
        "        self.biases = [torch.nn.Parameter(torch.zeros((1, 128))),\n",
        "                    torch.nn.Parameter(torch.zeros((1, 64))),\n",
        "                    torch.nn.Parameter(torch.zeros((1, 10)))]\n",
        "\n",
        "        self.activation = nn.ReLU()\n",
        "\n",
        "        \n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 784)\n",
        "        # TODO: Do the forward pass using matrix multiplications and applying activation functions\n",
        "        a = x.clone()\n",
        "        for i in range(len(self.weights) - 1):\n",
        "            # print(a)\n",
        "            # print(torch.matmul(a, self.weights[i]))\n",
        "            # print(\"weights\", self.weights[i])\n",
        "            # break\n",
        "            a = torch.matmul(a, self.weights[i]) + self.biases[i]\n",
        "            a = self.activation(a)\n",
        "    \n",
        "        a = torch.matmul(a, self.weights[-1]) + self.biases[-1]\n",
        "        # print(a)\n",
        "\n",
        "        return a"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Training the manual model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training ManualNet\n",
            "Epoch: 1, Loss: 170.86883544921875\n",
            "Epoch: 2, Loss: 55.97799301147461\n",
            "Epoch: 3, Loss: 43.24806213378906\n",
            "Epoch: 4, Loss: 35.61440658569336\n",
            "Epoch: 5, Loss: 30.802824020385742\n",
            "Epoch: 6, Loss: 26.88429832458496\n",
            "Epoch: 7, Loss: 24.12229347229004\n",
            "Epoch: 8, Loss: 21.355195999145508\n",
            "Epoch: 9, Loss: 18.976848602294922\n",
            "Epoch: 10, Loss: 17.51992416381836\n",
            "Accuracy: 96.52%\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nTraining ManualNet\")\n",
        "# TODO: Create a ManualNet object and call it manual_model. Train and test it\n",
        "manual_model = ManualNet()\n",
        "# manual_model = manual_model.to(device)\n",
        "# manual_model = manual_model.to(device)\n",
        "\n",
        "\n",
        "# x, y = next(iter(test_loader))\n",
        "# print(x[0].shape)\n",
        "# print(manual_model(x[:1]))\n",
        "\n",
        "#training \n",
        "\n",
        "batch_size = 256\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
        "\n",
        "rate = 0.1\n",
        "# why does loss = nn.CrossEntropyLoss(out, y) not work\n",
        "loss_fn  = nn.CrossEntropyLoss()\n",
        "\n",
        "# %pip install tqdm\n",
        "from tqdm import tqdm\n",
        "\n",
        "for j in range(10):\n",
        "# for i in tqdm(range(50000)):\n",
        "    # rate = 1/(math.sqrt(i+1))\n",
        "    total_loss = 0\n",
        "    for x, y in train_loader:\n",
        "        # x, y= x.to(device), y.to(device)\n",
        "        out = manual_model(x)\n",
        "\n",
        "        loss = (loss_fn(out, y))\n",
        "        loss.backward()\n",
        "        total_loss += loss\n",
        "\n",
        "        with torch.no_grad():\n",
        "\n",
        "            for i in range(len(manual_model.weights)):\n",
        "                manual_model.weights[i] -= rate*manual_model.weights[i].grad\n",
        "                manual_model.biases[i] -= rate*manual_model.biases[i].grad\n",
        "\n",
        "                # manual_model.weights[i].grad.zero_()\n",
        "                # manual_model.biases[i].grad.zero_()\n",
        "\n",
        "                manual_model.weights[i].grad /= 1.2\n",
        "                manual_model.biases[i].grad /= 1.2\n",
        "\n",
        "    print(f\"Epoch: {j+1}, Loss: {total_loss}\")\n",
        "    # if(i%1 == 0):\n",
        "\n",
        "test_cpu(manual_model, test_loader)\n",
        "            "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "batch size = 256, accuracy = 93.87, epochs =10, lr 0.01, SGD + momentum<br><br>\n",
        "batch size = 256, accuracy = 94.8,  epochs =10, lr 0.1, SGD<br><br>\n",
        "batch size = 256, accuracy = 95.9,  epochs =10, lr 0.05, SGD + momentum<br><br>\n",
        "batch size = 256, accuracy = 96.52, epochs =10, lr 0.1, SGD + momentum<br><br>\n",
        "\n",
        "This learning rate is very high but works for large batch size and SDG, but won't work with Adam so always start from like 0.0001 and go up"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Visualize the outputs of the models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Manual Model\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x200 with 5 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sequential Model\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x200 with 5 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "def visualize(model, model2, loader, n=5):\n",
        "    model.eval()\n",
        "    x, y = next(iter(loader))\n",
        "    preds = model(x).argmax(dim=1)\n",
        "    # x, y = x.to(device), y.to(device)\n",
        "    preds2 = model2(x).argmax(dim=1)\n",
        "\n",
        "    plt.figure(figsize=(10, 2))\n",
        "    i = 0\n",
        "    j = 0\n",
        "    \n",
        "    print(\"Manual Model\")\n",
        "    indicies = [0]*n\n",
        "    while True:\n",
        "        if y[i].item() != preds2[i].item():\n",
        "            plt.subplot(1, n, j+1)\n",
        "            plt.imshow(x[i].cpu().squeeze(), cmap='gray')\n",
        "            plt.title(f\"T:{y[i].item()} P:{preds2[i].item()}\")\n",
        "            plt.axis('off')\n",
        "            indicies[j] = i\n",
        "            j += 1\n",
        "            if j > 4:\n",
        "                break\n",
        "        i += 1\n",
        "    plt.show()\n",
        "    \n",
        "    print(\"Sequential Model\")\n",
        "    j = 0\n",
        "    plt.figure(figsize=(10, 2))\n",
        "    for i in indicies:\n",
        "        plt.subplot(1, n, j+1)\n",
        "        plt.imshow(x[i].cpu().squeeze(), cmap='gray')\n",
        "        plt.title(f\"T:{y[i].item()} P:{preds[i].item()}\")\n",
        "        plt.axis('off')\n",
        "        j += 1\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "test_loader = DataLoader(test_dataset, batch_size=1000, shuffle=True)\n",
        "# indicies = visualize(manual_model, test_loader, None, False) # Uncomment this later\n",
        "visualize(sequential_model, manual_model, test_loader)\n",
        "# visualize(manual_model, sequential_model, test_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K_ymh-5LLyMY"
      },
      "source": [
        "## Assignment\n",
        "* Load and preprocess CIFAR100 dataset (not CIFAR10)\n",
        "* Build a feedforward network for it. You can experiment around with number of layers and and neurons in each layer and different activation functions\n",
        "* You are allowed to use nn.functional. (convolutions _might_ make your accuracy better)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Bonus Assignment\n",
        "* Try the solving the \"Titanic Survival Prediction\" dataset from kaggle"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome To Colab",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
